{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eddbee-02af-4815-8392-88753c42fa07",
   "metadata": {},
   "source": [
    "$\\DeclareMathOperator*{\\argmin}{argmin}$\n",
    "$\\DeclareMathOperator*{\\argmax}{argmax}$\n",
    "$\\DeclareMathOperator{\\erf}{erf}$\n",
    "$\\DeclareMathOperator{\\erfc}{erfc}$\n",
    "$\\DeclareMathOperator{\\artanh}{artanh}$\n",
    "$\\DeclareMathOperator{\\expint}{expint}$\n",
    "$\\DeclareMathOperator{\\si}{si}$\n",
    "$\\DeclareMathOperator{\\sgn}{sgn}$\n",
    "$\\DeclareMathOperator{\\ld}{ld}$\n",
    "$\\DeclareMathOperator{\\rank}{rank}$\n",
    "$\\DeclareMathOperator{\\trace}{tr}$\n",
    "$\\DeclareMathOperator{\\Exp}{E}$\n",
    "$\\DeclareMathOperator*{\\condequal}{=}$\n",
    "$\\DeclareMathOperator*{\\condapprox}{\\approx}$\n",
    "$\\newcommand{\\wt}{wt_{\\rm{H}}}$\n",
    "$\\newcommand{\\distH}{d_{\\rm{H}}}$\n",
    "$\\newcommand{\\prob}[1]{{\\Pr \\left \\{ #1 \\right\\} }}$\n",
    "$\\newcommand{\\cdf}[2]{{P_{ #1 } \\! \\left( #2 \\right) }}$\n",
    "$\\newcommand{\\pdf}[2]{{p_{ #1 } \\! \\left( #2 \\right) }}$\n",
    "$\\newcommand{\\real}[1]{{\\mathrm{Re}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\imag}[1]{{\\mathrm{Im}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\rect}[1]{{\\mathrm{rect}\\left(#1\\right)}}$\n",
    "$\\newcommand{\\tri}[1]{{\\mathrm{tri}\\left(#1\\right)}}$\n",
    "$\\newcommand{\\diag}{{\\mathrm{diag}}}$\n",
    "$\\newcommand{\\sinc}{{\\mathrm{sinc}}}$\n",
    "$\\newcommand{\\gtx}[2]{{g_\\mathrm{tx}^{#2}\\!\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\gttx}[2]{{\\tilde{g}_{\\mathrm{tx}}^{#2}\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\grx}[2]{{g_\\mathrm{rx}^{#2}\\!\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\gtrx}[2]{{\\tilde{g}_{\\mathrm{rx}}^{#2}\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\Gtx}[1]{{G_\\mathrm{tx}\\!\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\Gttx}[1]{{\\tilde{G}_{\\mathrm{tx}}\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\Grx}[1]{{G_\\mathrm{rx}\\!\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\Gtrx}[1]{{\\tilde{G}_{\\mathrm{rx}}\\!\\left(#1\\right)}}$\n",
    "$\\newcommand{\\FT}[1]{{{\\cal F}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\IFT}[1]{{{\\cal F}^{-1}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\HT}[1]{{{\\cal H}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\IHT}[1]{{{\\cal H}^{-1}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\LT}[1]{{{\\cal L}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\ILT}[1]{{{\\cal L}^{-1}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\FFT}[1]{{\\mathrm{FFT}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\IFFT}[1]{{\\mathrm{IFFT}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\ZT}[1]{{{\\cal Z}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\IZT}[1]{{{\\cal Z}^{-1}\\left\\{#1\\right\\}}}$\n",
    "$\\newcommand{\\Hz}{{\\mathrm{\\:Hz}}}$\n",
    "$\\newcommand{\\kHz}{{\\mathrm{\\:kHz}}}$\n",
    "$\\newcommand{\\MHz}{{\\mathrm{\\:MHz}}}$\n",
    "$\\newcommand{\\GHz}{{\\mathrm{\\:GHz}}}$\n",
    "$\\newcommand{\\ms}{{\\mathrm{\\:ms}}}$\n",
    "$\\newcommand{\\mus}{{\\mathrm{\\:\\mu s}}}$\n",
    "$\\newcommand{\\kmh}{{\\mathrm{\\:km/h}}}$\n",
    "$\\newcommand{\\mps}{{\\mathrm{\\:m/s}}}$\n",
    "$\\newcommand{\\dB}{{\\mathrm{\\:dB}}}$\n",
    "$\\newcommand{\\kbits}{{\\mathrm{\\:kbit/s}}}$\n",
    "$\\newcommand{\\bit}{{\\mathrm{\\:bit}}}$\n",
    "$\\newcommand{\\kBaud}{{\\mathrm{\\:kBaud}}}$\n",
    "$\\newcommand{\\with}{\\quad\\mathrm{with}\\;\\,}$\n",
    "$\\newcommand{\\for}{\\,\\mathrm{for}\\;}$\n",
    "$\\newcommand{\\Else}{\\,\\mathrm{else}\\;}$\n",
    "$\\newcommand{\\SNR}{{SNR}}$\n",
    "$\\newcommand{\\EbNO}{{E_{\\mathrm{b}}/N_0}}$\n",
    "$\\newcommand{\\EbNOdB}{{10 \\log_{10}(E_{\\mathrm{b}}/N_0)}}$\n",
    "$\\newcommand{\\EsNO}{{E_{\\mathrm{s}}/N_0}}$\n",
    "$\\newcommand{\\EsNOdB}{{10 \\log_{10}(E_{\\mathrm{s}}/N_0)}}$\n",
    "$\\newcommand{\\sigmaX}{{\\sigma_{\\sproc{X}}^2}}$\n",
    "$\\newcommand{\\sigmaD}{{\\sigma_{\\sproc{D}}^2}}$\n",
    "$\\newcommand{\\sigmaS}{{\\sigma_{\\sproc{S}}^2}}$\n",
    "$\\newcommand{\\sigmaH}{{\\sigma_{\\sproc{H}}^2}}$\n",
    "$\\newcommand{\\sigmaN}{{\\sigma_{\\sproc{N}}^2}}$\n",
    "$\\newcommand{\\sigmaY}{{\\sigma_{\\sproc{Y}}^2}}$\n",
    "$\\renewcommand{\\vec}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\av}{\\vec{a}}$\n",
    "$\\newcommand{\\bv}{\\vec{b}}$\n",
    "$\\newcommand{\\cv}{\\vec{c}}$\n",
    "$\\newcommand{\\dv}{\\vec{d}}$\n",
    "$\\newcommand{\\ev}{\\vec{e}}$\n",
    "$\\newcommand{\\fv}{\\vec{f}}$\n",
    "$\\newcommand{\\gv}{\\vec{g}}$\n",
    "$\\newcommand{\\hv}{\\vec{h}}$\n",
    "$\\newcommand{\\iv}{\\vec{i}}$\n",
    "$\\newcommand{\\jv}{\\vec{j}}$\n",
    "$\\newcommand{\\kv}{\\vec{k}}$\n",
    "$\\newcommand{\\lv}{\\vec{l}}$\n",
    "$\\newcommand{\\mv}{\\vec{m}}$\n",
    "$\\newcommand{\\nv}{\\vec{n}}$\n",
    "$\\newcommand{\\ov}{\\vec{o}}$\n",
    "$\\newcommand{\\pv}{\\vec{p}}$\n",
    "$\\newcommand{\\qv}{\\vec{q}}$\n",
    "$\\newcommand{\\rv}{\\vec{r}}$\n",
    "$\\newcommand{\\sv}{\\vec{s}}$\n",
    "$\\newcommand{\\tv}{\\vec{t}}$\n",
    "$\\newcommand{\\uv}{\\vec{u}}$\n",
    "$\\newcommand{\\vv}{\\vec{v}}$\n",
    "$\\newcommand{\\wv}{\\vec{w}}$\n",
    "$\\newcommand{\\xv}{\\vec{x}}$\n",
    "$\\newcommand{\\yv}{\\vec{y}}$\n",
    "$\\newcommand{\\zv}{\\vec{z}}$\n",
    "$\\newcommand{\\zerov}{\\vec{0}}$\n",
    "$\\newcommand{\\onev}{\\vec{1}}$\n",
    "$\\newcommand{\\alphav}{\\vecs{\\alpha}}$\n",
    "$\\newcommand{\\betav}{\\vecs{\\beta}}$\n",
    "$\\newcommand{\\varepsilonv}{\\vecs{\\varepsilon}}$\n",
    "$\\newcommand{\\gammav}{\\vecs{\\gamma}}$\n",
    "$\\newcommand{\\lambdav}{\\vecs{\\lambda}}$\n",
    "$\\newcommand{\\muv}{\\vecs{\\mu}}$\n",
    "$\\newcommand{\\omegav}{\\vecs{\\omega}}$\n",
    "$\\newcommand{\\sigmav}{\\vecs{\\sigma}}$\n",
    "$\\newcommand{\\thetav}{\\vecs{\\theta}}$\n",
    "$\\newcommand{\\psiv}{\\vecs{\\psi}}$\n",
    "$\\newcommand{\\phiv}{\\vecs{\\phi}}$\n",
    "$\\newcommand{\\zetav}{\\vecs{\\zeta}}$\n",
    "$\\newcommand{\\Am}{\\vec{A}}$\n",
    "$\\newcommand{\\Bm}{\\vec{B}}$\n",
    "$\\newcommand{\\Cm}{\\vec{C}}$\n",
    "$\\newcommand{\\Dm}{\\vec{D}}$\n",
    "$\\newcommand{\\Em}{\\vec{E}}$\n",
    "$\\newcommand{\\Fm}{\\vec{F}}$\n",
    "$\\newcommand{\\Gm}{\\vec{G}}$\n",
    "$\\newcommand{\\Hm}{\\vec{H}}$\n",
    "$\\newcommand{\\Id}{\\vec{I}}$\n",
    "$\\newcommand{\\Jm}{\\vec{J}}$\n",
    "$\\newcommand{\\Km}{\\vec{K}}$\n",
    "$\\newcommand{\\Lm}{\\vec{L}}$\n",
    "$\\newcommand{\\Mm}{\\vec{M}}$\n",
    "$\\newcommand{\\Nm}{\\vec{N}}$\n",
    "$\\newcommand{\\Om}{\\vec{O}}$\n",
    "$\\newcommand{\\Pm}{\\vec{P}}$\n",
    "$\\newcommand{\\Qm}{\\vec{Q}}$\n",
    "$\\newcommand{\\Rm}{\\vec{R}}$\n",
    "$\\newcommand{\\Sm}{\\vec{S}}$\n",
    "$\\newcommand{\\Tm}{\\vec{T}}$\n",
    "$\\newcommand{\\Um}{\\vec{U}}$\n",
    "$\\newcommand{\\Vm}{\\vec{V}}$\n",
    "$\\newcommand{\\Wm}{\\vec{W}}$\n",
    "$\\newcommand{\\Xm}{\\vec{X}}$\n",
    "$\\newcommand{\\Ym}{\\vec{Y}}$\n",
    "$\\newcommand{\\Zm}{\\vec{Z}}$\n",
    "$\\newcommand{\\Arv}{{\\cal A}}$\n",
    "$\\newcommand{\\Brv}{{\\cal B}}$\n",
    "$\\newcommand{\\Crv}{{\\cal C}}$\n",
    "$\\newcommand{\\Drv}{{\\cal D}}$\n",
    "$\\newcommand{\\Erv}{{\\cal E}}$\n",
    "$\\newcommand{\\Frv}{{\\cal F}}$\n",
    "$\\newcommand{\\Grv}{{\\cal G}}$\n",
    "$\\newcommand{\\Hrv}{{\\cal H}}$\n",
    "$\\newcommand{\\Irv}{{\\cal I}}$\n",
    "$\\newcommand{\\Jrv}{{\\cal J}}$\n",
    "$\\newcommand{\\Krv}{{\\cal K}}$\n",
    "$\\newcommand{\\Lrv}{{\\cal L}}$\n",
    "$\\newcommand{\\Mrv}{{\\cal M}}$\n",
    "$\\newcommand{\\Nrv}{{\\cal N}}$\n",
    "$\\newcommand{\\Orv}{{\\cal O}}$\n",
    "$\\newcommand{\\Prv}{{\\cal P}}$\n",
    "$\\newcommand{\\Qc}{{\\cal Q}}$\n",
    "$\\newcommand{\\Rrv}{{\\cal R}}$\n",
    "$\\newcommand{\\Srv}{{\\cal S}}$\n",
    "$\\newcommand{\\Trv}{{\\cal T}}$\n",
    "$\\newcommand{\\Urv}{{\\cal U}}$\n",
    "$\\newcommand{\\Wrv}{{\\cal W}}$\n",
    "$\\newcommand{\\Vrv}{{\\cal V}}$\n",
    "$\\newcommand{\\Xrv}{{\\cal X}}$\n",
    "$\\newcommand{\\Yrv}{{\\cal Y}}$\n",
    "$\\newcommand{\\Zrv}{{\\cal Z}}$\n",
    "$\\newcommand{\\Arvvec}{\\mathbfcal{A}}$\n",
    "$\\newcommand{\\Brvvec}{\\mathbfcal{B}}$\n",
    "$\\newcommand{\\Crvvec}{\\mathbfcal{C}}$\n",
    "$\\newcommand{\\Drvvec}{\\mathbfcal{D}}$\n",
    "$\\newcommand{\\Ervvec}{\\mathbfcal{E}}$\n",
    "$\\newcommand{\\Frvvec}{\\mathbfcal{F}}$\n",
    "$\\newcommand{\\Grvvec}{\\mathbfcal{G}}$\n",
    "$\\newcommand{\\Hrvvec}{\\mathbfcal{H}}$\n",
    "$\\newcommand{\\Irvvec}{\\mathbfcal{I}}$\n",
    "$\\newcommand{\\Jrvvec}{\\mathbfcal{J}}$\n",
    "$\\newcommand{\\Krvvec}{\\mathbfcal{K}}$\n",
    "$\\newcommand{\\Lrvvec}{\\mathbfcal{L}}$\n",
    "$\\newcommand{\\Mrvvec}{\\mathbfcal{M}}$\n",
    "$\\newcommand{\\Nrvvec}{\\mathbfcal{N}}$\n",
    "$\\newcommand{\\Orvvec}{\\mathbfcal{O}}$\n",
    "$\\newcommand{\\Prvvec}{\\mathbfcal{P}}$\n",
    "$\\newcommand{\\Qrvvec}{\\mathbfcal{Q}}$\n",
    "$\\newcommand{\\Rrvvec}{\\mathbfcal{R}}$\n",
    "$\\newcommand{\\Srvvec}{\\mathbfcal{S}}$\n",
    "$\\newcommand{\\Trvvec}{\\mathbfcal{T}}$\n",
    "$\\newcommand{\\Urvvec}{\\mathbfcal{U}}$\n",
    "$\\newcommand{\\Wrvvec}{\\mathbfcal{W}}$\n",
    "$\\newcommand{\\Vrvvec}{\\mathbfcal{V}}$\n",
    "$\\newcommand{\\Xrvvec}{\\mathbfcal{X}}$\n",
    "$\\newcommand{\\Yrvvec}{\\mathbfcal{Y}}$\n",
    "$\\newcommand{\\Zrvvec}{\\mathbfcal{Z}}$\n",
    "$\\newcommand{\\CC}{\\mathbb{C}}$\n",
    "$\\newcommand{\\EE}{{\\mathds{E}}}$\n",
    "$\\newcommand{\\MM}{\\mathbb{M}}$\n",
    "$\\newcommand{\\NN}{\\mathbb{N}}$\n",
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\renewcommand{\\SS}{\\mathbb{S}}$\n",
    "$\\newcommand{\\cSS}{\\overline{\\mathbb{S}}}$\n",
    "$\\newcommand{\\XX}{\\mathbb{X}}$\n",
    "$\\newcommand{\\YY}{\\mathbb{Y}}$\n",
    "$\\newcommand{\\ZZ}{\\mathbb{Z}}$\n",
    "\n",
    "$\\newcommand{\\dc}{{d_{\\mathrm{c}}}}$\n",
    "$\\newcommand{\\df}{{d_{\\rm f}}}$\n",
    "$\\newcommand{\\dH}{{d_{\\rm H}}}$\n",
    "$\\newcommand{\\dv}{{d_{\\mathrm{v}}}}$\n",
    "$\\newcommand{\\wH}{{w_{\\rm H}}}$\n",
    "$\\newcommand{\\GF}{{\\rm GF}}$\n",
    "$\\newcommand{\\gc}{{g_\\mathrm{c}}}$\n",
    "$\\newcommand{\\gd}{{g_\\mathrm{d}}}$\n",
    "$\\newcommand{\\gr}{{g_\\mathrm{R}}}$\n",
    "$\\newcommand{\\Gr}{{G_\\mathrm{R}}}$\n",
    "$\\newcommand{\\gt}{{g_\\mathrm{T}}}$\n",
    "$\\newcommand{\\Gt}{{G_\\mathrm{T}}}$\n",
    "$\\newcommand{\\fd}{{f_{\\rm d}}}$\n",
    "$\\newcommand{\\fN}{{f_\\mathrm{N}}}$\n",
    "$\\newcommand{\\La}{{L_{\\rm a}}}$\n",
    "$\\newcommand{\\Le}{{L_{\\rm e}}}$\n",
    "$\\newcommand{\\Lc}{{L_{\\rm c}}}$\n",
    "$\\newcommand{\\Lh}{{L_{\\rm h}}}$\n",
    "$\\newcommand{\\Lp}{{L_{\\rm p}}}$\n",
    "$\\newcommand{\\Lt}{{L_{\\rm t}}}$\n",
    "$\\newcommand{\\Lx}{{L_{\\mathrm{X}}}}$\n",
    "$\\newcommand{\\Nc}{{N_{\\rm c}}}$\n",
    "$\\newcommand{\\Np}{{N_{\\rm p}}}$\n",
    "$\\newcommand{\\Nr}{{N_{\\rm r}}}$\n",
    "$\\newcommand{\\Nv}{{N_{\\rm v}}}$\n",
    "$\\newcommand{\\Eg}{{E_{\\rm G}}}$\n",
    "$\\newcommand{\\Eb}{{E_{\\rm b}}}$\n",
    "$\\newcommand{\\Es}{{E_{\\rm s}}}$\n",
    "$\\newcommand{\\Pb}{{P_{\\rm b}}}$\n",
    "$\\newcommand{\\Pe}{{P_{\\rm e}}}$\n",
    "$\\newcommand{\\Pf}{{P_{\\rm f}}}$\n",
    "$\\newcommand{\\Ps}{{P_{\\rm s}}}$\n",
    "$\\newcommand{\\Pt}{{P_{\\rm{t}}}}$\n",
    "$\\newcommand{\\Pw}{{P_{\\rm w}}}$\n",
    "$\\newcommand{\\Pout}{{P_{\\rm out}}}$\n",
    "$\\newcommand{\\Rc}{R_{\\mathrm c}}$\n",
    "$\\newcommand{\\Rh}{{R_{\\rm h}}}$\n",
    "$\\newcommand{\\Tb}{{T_{\\rm b}}}$\n",
    "$\\newcommand{\\Tc}{{T_{\\rm c}}}$\n",
    "$\\newcommand{\\tc}{{t_{\\rm c}}}$\n",
    "$\\newcommand{\\Tg}{{T_{\\rm g}}}$\n",
    "$\\newcommand{\\Ts}{{T_{\\rm s}}}$\n",
    "$\\newcommand{\\Cout}{{C_{\\rm out}}}$\n",
    "$\\newcommand{\\Ia}{{I_{\\mathrm{a}}}}$\n",
    "$\\newcommand{\\Ie}{{I_{\\mathrm{e}}}}$\n",
    "$\\newcommand{\\Ip}{{I_{\\mathrm{p}}}}$\n",
    "$\\newcommand{\\It}{{I_{\\mathrm{tot}}}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b768d-5d84-4ffd-aab4-c1aa745d5a12",
   "metadata": {},
   "source": [
    "# 10. Low-Density Parity Check (LDPC) Codes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ad121-7b61-4001-a636-b379a711e001",
   "metadata": {},
   "source": [
    "## 10.1 Code Properties<a class=\"anchor\" id=\"CodeProperties\"></a>\n",
    "\n",
    "Low Density Partity Check codes habe been invented by Robert Gallager in 1963. The are conventional linear block codes with the particular property that the parity check matrix $\\Hm$ is spare, i.e. it contains only a few ones. This property enables efficient and powerful soft-input decoding which is not possible for arbitrary linear block codes (see [MessagePassingDecoding](#MessagePassingDecoding)). Even though Gallager pointed out basic properties of LDPC codes including a code construction, it took several decades before current technology enables the application of these codes in practical systems. Today, they are applied in 4G and 5G cellular mobile communication as well as WiFI systems.\n",
    "\n",
    "LDPC codes are defined by their $N \\times n$ parity check matrix $\\Hm$. As for conventional linear block codes, $\\cv \\cdot \\Hm^{\\mathrm{T}}=\\mathbf{0}$ holds for all code words $\\cv \\in \\Gamma$. Hence, $\\Gamma$ is the null space of $\\Hm$. Regular and irregular LDPC codes are distinguished. While regular ones have a constant number of ones in each row or column, the number of ones per row/column can vary for irregular codes. Since this allows a larger degree of freedom, irregular LDPC codes generally perform better than regular LDPC codes.\n",
    "\n",
    "**Definition of Regular LDPC code: [Lin, Costello 2004]**\n",
    "\n",
    "An LDPC code is defined as the null space of a parity check matrix $\\Hm$ with properties:\n",
    "* each row consists of $\\Nr$ ones (check nodes with degree $\\Nr$)\n",
    "* each column consists of $\\Nc$ ones (variable nodes with degree $\\Nc$)\n",
    "* number of 1's in common between any two columns not larger than 1\n",
    "* $\\Nc$ and $\\Nr$ are small compared to $N$ and $n$, i.e. $\\Hm$ is sparse, number of ones is small compared to size of $\\Hm$ (low density)\n",
    "\n",
    "An example of a parity check matrix for a cyclic (15,6) LDPC code with $\\Nr=3$ and $\\Nc=2$ is given below. The number of rows $N$ may differ from $n-k$ representing number of independent rows in $\\Hm$. The rank of the parity check matrix is $\\mathrm{rank}(\\Hm)=9$. As a consequence, the null space of $\\Hm$ has dimension $k=15-9=6$. The density of the code amounts to $\\rho = \\frac{\\Nr}{n} = \\frac{3}{15} = \\frac{\\Nc}{J} = \\frac{2}{10}=0.2$.\n",
    "\n",
    "\\begin{align}\n",
    "    \\Hm &= \\left[\n",
    "        \\begin{array}{ccccc|*ccccc|*ccccc}\n",
    "            1 & \\cdot & \\cdot & \\cdot & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "            1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "            \\cdot & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "            \\cdot & \\cdot & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "            \\cdot & \\cdot & \\cdot & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\ \\hline\n",
    "            \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 \\\\\n",
    "            \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & 1 & 1 & \\cdot & \\cdot & \\cdot \\\\\n",
    "            \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & 1 & \\cdot & \\cdot \\\\\n",
    "            \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & 1 & 1 & \\cdot \\\\\n",
    "            \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & 1 \\\\\n",
    "        \\end{array} \\right]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "**Construction of LDPC Codes**\n",
    "\n",
    "Various approaches for the construction of powerful LDPC codes exist. Basically, the parity check matrix $\\Hm$ has to be designed. Similar to pseudo-random interleavers for turbo codes, a *random code construction* can lead to powerful LDPC codes.\n",
    "1. Randomly select new column with $\\Nc$ 1's\n",
    "2. If a new column has more than a single 1 in common with old columns or violates row norm $\\Nr$, it is rejected\n",
    "3. Otherwise keep the new column and continue with step 1. until $n$ columns are obtained\n",
    "\n",
    "An example for the construction of regular LDPC Codes according to Gallager is explained now. It proves a $k \\Nr \\times k \\Nc$ matrix $\\Hm$.\n",
    "* Parity check matrix comprises $k \\times k \\Nr$ sub-matrices $\\Hm_j$: $\\Hm = \\begin{bmatrix} \\Hm_1^{\\mathrm{T}} & \\Hm_2^{\\mathrm{T}} & \\cdots & \\Hm_J^{\\mathrm{T}} \\end{bmatrix}^{\\mathrm{T}}$\n",
    "    *  Each sub-matrix $\\Hm_j$ has $\\Nr$ 1's per row, but a single 1 in each column only \n",
    "    * $i$th row of sub-matrix $\\Hm_1$ has its 1's in columns $(i-1)\\Nr+1$ to $i\\Nr$\n",
    "    * Further sub-matrices $\\Hm_{j > 1}$ consist of column permutations of $\\Hm_1$\n",
    "* No constructive way known to determine suited permutations (computer searches needed)\n",
    "* For very long codes, powerful permutations have been found leading to performance very close to Shannon limits\n",
    "\n",
    "Alternatively, sophisticated *algebraic construction by finite geometry* can be used. Example are Euclidean Geometry and Projective Geometry LDPC codes.\n",
    "\n",
    "Example for code construction by Gallager with $n=20$, $\\Nr=4$, $J=3$\n",
    "* Each row has $\\Nr=4$ ones, each column only a single 1\n",
    "* $J=3$ sub-matrices each of size $k \\times k \\Nr = 5 \\times 20$ \n",
    "* First 5 rows represent  $\\Hm_1$ with consecutive 1's in each row (non-overlapping)\n",
    "* Sub-matrices $\\Hm_2$ and $\\Hm_3$ obtained by permuting columns of $\\Hm_1$\n",
    "\n",
    "\\begin{align}\n",
    "    \\Hm &= \n",
    "    \\left[\n",
    "    \\begin{array}{cccc|cccc|cccc|cccc|cccc}\n",
    "        1 & 1 & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & \\cdot & 1 & 1 & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & 1 & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & 1 & 1 & 1 & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & 1 & 1 & 1 \\\\ \\hline\n",
    "        1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 \\\\ \\hline\n",
    "        1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot \\\\\n",
    "        \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot \\\\\n",
    "        \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 & \\cdot & \\cdot & \\cdot & \\cdot & 1 \n",
    "    \\end{array} \\right]\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be1d5a1-0414-4d40-a61a-2b2aa59503ea",
   "metadata": {},
   "source": [
    "## 10.2 Message Passing Decoding (Belief Propagation)<a class=\"anchor\" id=\"MessagePassingDecoding\"></a>\n",
    "\n",
    "As LDPC codes belong the the class of linear block codes, conventional decoding algorithms can be applied. However, conceptually simple hard decision decoding algorithms are not the favorite choice. On the one hand, optimal maximum likelihood syndrome decoding quickly becomes infeasible due to large tables of syndromes and coset leaders to be stored. On the other hand, majority logic decoding or bit-flipping decoding algorithms are very efficient but have quite poor performance. Optimal soft-input MAP decoding also have a huge complexity and cannot be implemented except for very short codes.\n",
    "\n",
    "Regarding efficient and powerful LDPC decoding, it is helpful to represent the code graphically by a bipartite Tanner graph. As depicted in the figure below, it consists of $n$ variable nodes and $J$ check nodes. For this toy example, $n=6$ and $J=3$ hold.\n",
    "\n",
    "<img src=\"Figures/part4_bipartite_factor_graph.png\" width=400 ref={part4_bipartite_factor_graph}/>\n",
    "\n",
    "Based on the graph, iterative message passing algorithms also known as Sum-Product or Belief Propagation algorithm can be developed. Messages are passed forth and back over the edges between connected nodes. For binary LDPC codes as considered in this exercise, LLRs can be used as messages. Similar to turbo decoding, only extrinsic LLRs are exchanged for between variable and check nodes. Both types of nodes perform unique operations. \n",
    "\n",
    "* Check node $j$ obtains messages $L_{\\mathrm{v}}^{(i \\to j)}$ from all variable nodes $i \\in \\NN_\\mathrm{c}(j)$. The set $\\NN_\\mathrm{c}(j)$ denotes the neighborhood of check node $j$, i.e. all variable nodes $i$ connected to it. As check nodes represent check equations similar to  SPC codes, the incoming LLRs are \"box-plused\". Since only extrinsic LLRs must be exchanged, the message generated at check node $j$ for variable node $i$ has to exclude the LLR $L_{\\mathrm{v}}^{(i \\to j)}$ obtained from variable node $i$. Hence, we obtain the processing rule \n",
    "\\begin{align*}\n",
    "    L_\\mathrm{c,e}^{(j \\to i)} \n",
    "    &= \\log \\frac{ 1 + \\prod_{\\nu \\in \\NN_\\mathrm{c}(j) \\setminus \\{i\\}} \\tanh \\left(L_{\\mathrm{v,e}}^{(\\nu \\to i)}/2 \\right) }\n",
    "                 { 1 - \\prod_{\\nu \\in \\NN_\\mathrm{c}(j) \\setminus \\{i\\}} \\tanh \\left(L_{\\mathrm{v,e}}^{(\\nu \\to i)}/2 \\right) } \n",
    "     = 2 \\artanh \\left[ \\prod_{\\nu \\in \\NN_\\mathrm{c}(j) \\setminus \\{i\\}}  \\tanh \\left( \\frac{L_{\\mathrm{v,e}}^{(\\nu \\to i)}}{2} \\right) \\right] \n",
    "\\end{align*}\n",
    "* As shown in the lecture, the exact computation of the extrinsic LLRs can be approximated by multiplying the product of all signs with the minimum magnitude of all input LLRs. The decoding algorithm based on this approximation is termed min-sum algorithm.\n",
    "* These extrinsic LLRs are collected by the variable nodes. They represent beliefs of the value of a particular variable node. Since they stem from different check nodes, they  are assumed to be independent of each other. Hence, they are simply summed as for decoding repetition codes. We obtain\n",
    "\\begin{align}\n",
    "    L_\\mathrm{v}^{(i)} &= L_\\mathrm{ch} \\cdot y_i + \\sum_{j \\in \\NN_\\mathrm{v}(i)} L_\\mathrm{c,e}^{(j \\to i)} \\ .\n",
    "\\end{align}\n",
    "The set $\\NN_\\mathrm{v}(i)$ denotes the neighborhood of variable node $i$, i.e. all check nodes $j$ connected to it. If the graph contains loops, the extrinsic LLRs $L_\\mathrm{c,e}^{(j \\to i)}$ become more and more correlated and the independence assumption does not hold any longer. However, improvements can still be obtained if the girth (length) of the loops is large. Hence, designing LDPC codes requires to design Tanner graphs with large girth!\n",
    "* With the two steps described above, the first iteration is finished. Principally, the next iteration starts as the previous one, just with improved messages. Thereby, only the extrinsic part of the LLRs must be forwarded to the check nodes. We obtain \n",
    "\\begin{align}\n",
    "    L_\\mathrm{v,e}^{(i \\to j)} &= L_\\mathrm{ch} \\cdot y_i + \\sum_{\\nu \\in \\NN_\\mathrm{v}(i) \\setminus \\{j\\} } L_\\mathrm{c,e}^{(\\nu \\to i)} \\ .\n",
    "\\end{align}\n",
    "* The iterative process continues until a convergence criterion is met. This might be the computation of the syndrome from the hard decisions at the end of each iteration. If the syndrome equals the all-zero-vector, a valid codeword has been found and the decoding process stops.\n",
    "* Short cycles lead to high correlations among associated signals reducing the gain per iteration significantly. In this case, the iterative sum product algorithm might get stuck far away from ML solution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0288a30f-07ca-49e2-85e8-e6c83388a2d9",
   "metadata": {},
   "source": [
    "## Exercise 10.1: Monte-Carlo Simulation of Petersen Code\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "1. Use the Monte-Carlo simulation environment of previous exercises and adapt it for the simulations of the Petersen LDPC code. It's code parameters can be found in the text file 'PetersenCode.txt' which uses the alist format. You can use the class 'LDPC' of the 'eccpythonlibrary'.\n",
    "2. Determine the main code parameters like length $n$, number of information bits $k$, code rate $\\Rc$, and the variable and check node degrees.\n",
    "3. Run Monte-Carlo simulations for an SNR range of [-10 dB, 5 dB] and 10 decoding iterations. Plot the resulting bit error rates versus $\\EsNO$ and $\\EbNO$. Describe your observations.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abdda99e-283e-4466-a269-8c22951cc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "eccPath = 'ECCpython'\n",
    "if (not eccPath in sys.path):\n",
    "    sys.path.append(eccPath)\n",
    "                \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from LDPC.ldpc import LDPC\n",
    "\n",
    "\n",
    "L = LDPC(eccPath + \"/LDPC/alist_files/PetersenCode.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f4f03-0a8f-48be-bb46-6d9072ce0421",
   "metadata": {},
   "source": [
    "## EXIT Chart Analysis<a class=\"anchor\" id=\"EXITchartAnalysis\"></a>\n",
    "\n",
    "The EXIT chart analysis for LDPC codes can be applied by realizing that the variable nodes represent repetition codes, and the check nodes represent single parity check codes. Please note that the following analysis tightly predicts the convergence behavior of the message passing decoding only for long codes with at least several thousand code bits. For short codes like the Peterson code considered above, significant deviations from the prediction can occur. Intuitive online demonstrations can be found at [Demo1](https://webdemo.inue.uni-stuttgart.de/webdemos/03_theses/ldpcExit/index.php?id=0https://webdemo.inue.uni-stuttgart.de/webdemos/03_theses/ldpcExit/index.php?id=0) and [Demo2](https://webdemo.inue.uni-stuttgart.de/webdemos/02_lectures/MEC/LDPC_degree_distribution/index.php?id=0).\n",
    "\n",
    "**Variable Nodes**\n",
    "\n",
    "Focusing first on an arbitrary variable nodes $i$, we see that one incoming signal is the channel output LLR $L(y_i|x_i)$. The remaining $d_{\\mathrm{v},i}$ inputs are the beliefs $L_{\\mathrm{c,e}}^{(j \\to i)}$ of connected check nodes $j \\in \\NN_{\\mathrm{v},i}$ about the value of symbol $x_i$. The number $d_{\\mathrm{v},i}$ represents the degree of the variable node $i$, i.e. the cardinality $|\\NN_{\\mathrm{v},i}|$ meaning the number of connections to check nodes. For regular LDPC codes, $d_{\\mathrm{v},i}$ is constant w.r.t. index $i$. For irregular codes, it varies with $i$ resulting in a certain degree distribution $\\Pr\\{ d_{\\mathrm{v},i} \\}$. The summation of these LLRs as described above resembles the decoding of an $(n,1)$ repetition code with $n=d_{\\mathrm{v},i}+1$. Thereby, it has to be considered that $L(y_i|x_i)$ depends on the channel SNR while $L_{\\mathrm{c,e}}^{(j \\to i)}$ are independent of the channel SNR. The latter represent the a priori information $I_{\\mathrm{c,a}}$ to be injected into the variable nodes and is artificially generated according to the EXIT chart philosophy.\n",
    "\n",
    "The a priori and extrinsic mutual information terms can be numerically computed as carried out before. Alternatively, they can be analytically determined by\n",
    "\n",
    "\\begin{align}\n",
    "    I_{\\mathrm{v,e}}\n",
    "    &= J \\left( (\\dv-1) \\cdot J^{-1} \\left( I_{\\mathrm{v,a}} \\right) + 8 \\frac{\\Es}{N_0} \\right)\n",
    "\\end{align}\n",
    "\n",
    "where $I_\\mathrm{a} = J(\\sigma_\\mathrm{a}^2)$ denotes the a priori mutual information as a function of the noise variance $\\sigma_\\mathrm{a}^2$ and $J(\\cdot)^{-1}$ its inverse. For irregular codes with varying $d_{\\mathrm{v},i}$, the mutual information values for different degrees need to be averaged leading to  \n",
    "\n",
    "\\begin{align}\n",
    "    I_{\\mathrm{v,e}}\n",
    "    &= \\sum_{d=1}^{d_{\\mathrm{v},\\max}} \\Pr\\{ d \\} \\cdot J \\left( (d-1) \\cdot J^{-1} \\left( I_{\\mathrm{v,a}} \\right) + 8 \\frac{\\Es}{N_0} \\right) \\ .\n",
    "\\end{align}\n",
    "\n",
    "**Check Nodes**\n",
    "\n",
    "Regarding an arbitrary check node $j$, the $d_{\\mathrm{c},j}$ incoming signals are beliefs of the connected variable nodes $i \\in \\NN_{\\mathrm{c},j}$ about their associated code bits which have to fulfill the parity check constraint represented by check node $j$. The number $d_{\\mathrm{c},j}$ denotes the degree of check node $j$. The parity check constraint resembles an SPC code, which is soft-decoded by box-plusing the incoming LLRs. In particular, the extrinsic LLR $L_{\\mathrm{c,e}}^{(j \\to i)}$ is obtained by excluding the incoming LLR from node $i$ from the box-plus operation. The a priori and extrinsic mutual information terms for the check nodes can be numerically computed as carried out before. Alternatively, they can be analytically determined by\n",
    "\n",
    "\\begin{align}\n",
    "    I_{\\mathrm{c,e}}\n",
    "    &= 1 - J \\left( (\\dc-1) \\cdot J^{-1} \\left( 1 - I_{\\mathrm{c,a}} \\right) \\right) \\ .\n",
    "\\end{align}\n",
    "\n",
    "For irregular codes with varying $d_{\\mathrm{c},j}$, the mutual information values for different degrees need to be averaged leading to  \n",
    "\n",
    "\\begin{align}\n",
    "    I_{\\mathrm{c,e}}\n",
    "    &= 1 - \\sum_{d=1}^{d_{\\mathrm{c},\\max}} \\Pr\\{ d \\} \\cdot J \\left( (d-1) \\cdot J^{-1} \\left( 1 - I_{\\mathrm{c,a}} \\right) \\right) \\ .\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecce1e1-7e9a-402b-b6da-a4de791806ab",
   "metadata": {},
   "source": [
    "## Exercise 10.2: EXIT Analysis of Variable Nodes (Repetition Codes)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "1. Analyze the EXIT behaviour of the variable nodes for node degrees $\\dv \\in \\{1,2,3,4,5\\}$ and SNRs $\\EsNOdB \\in$ [-10 dB, 5 dB] in 1dB steps. Model the a priori LLRs as done in previous exercises with a resolution of $0.1$ bit/s/Hz. Be aware that one input of a variable node comes from the channel output and, therefore, depends on the SNR. The remaining $d_\\mathrm{v}$ inputs are only affected by the mutual a priori information $I_{\\mathrm{v,a}}$. Hence, the length of the repetition code is $n=\\dv+1$.\n",
    "2. Compute the analytical transfer characteristic from the equations given above with a fine resolution of $0.001$ bit/s/Hz.\n",
    "3. Describe your observations.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33705a61-62a0-4a3b-b64b-80333afbd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BlockCodes.repetition import Repetition\n",
    "from EXIT.info_theory import mi_awgn, calc_MI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a6a87-32a0-49b3-9692-5406b51c04ca",
   "metadata": {},
   "source": [
    "## Exercise 10.3: EXIT Analysis of Check Nodes (SPC Codes)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "1. Analyze the EXIT behaviour of the check nodes for node degrees $\\dc \\in \\{3,4,5,6,7\\}$. Model the a priori LLRs as done in previous exercises. \n",
    "2. Compute the analytical transfer characteristic from the equations given above.\n",
    "3. Describe your observations.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c395a3-ba15-4f9a-b9bf-d3d530bf39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BlockCodes.spc import SPC\n",
    "\n",
    "# lengths of SPC codes (number of information bits), node degree is dc=k+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e90bb4-d30f-4518-8268-c39862cd782a",
   "metadata": {},
   "source": [
    "## Exercise 10.4: EXIT Charts of LDPC Code\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "1. Plot the transfer characteristics $\\Ie=f(\\Ia)$ for variable and check nodes of the original Petersen code by selecting the corresponding degrees for variable and check nodes for different SNRs. Use the fine resolution analytical mutual information. Describe your observations!\n",
    "2. Determine the pinch-off SNR above which the message passing algorithm converges.\n",
    "3. Construct the EXIT chart for the pinch-off SNR. How many decoding iterations are approximately needed to converge to the point $(\\Ia,\\Ie)=(1,1)$?\n",
    "4. Determine the transfer characteristic $\\Ie=f(\\Ia)$ for true message passing decoding of the Petersen code and plot the EXIT chart. How do theoretical and true message passing decoding match?\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545961d-fb62-44ce-8687-13b6a7787212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5cc6c-aeaf-41dd-8e5b-c9ca74f5e0c0",
   "metadata": {},
   "source": [
    "## Exercise 10.5: Optimizing LDPC Codes by Curve-Fitting\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "In this exercise, we optimize the LDPC code by choosing appropriate variable and check node degrees. Moreover, a simple irregular LDPC code is investigated by choosing a mixture of check node degrees which has to be optimized. For all parts of this exercise, use the analytically determined mutual information.\n",
    "\n",
    "1. Plot the curves $\\Ie=f(\\Ia)$ for all variable node degrees considered above into one diagram for an SNR of -8 dB. Add the curve $\\Ie=f^{-1}(\\Ia)$ for the check node with degree $\\dc=3$. Describe your observations!\n",
    "2. Select a suitable degree $d_\\mathrm{v}$ of the variable node for $d_\\mathrm{c}=3$ and plot the associated EXIT chart. Describe your observations \n",
    "3. Keep $d_\\mathrm{c}=3$ and optimize the combination of $d_\\mathrm{v}=2$ with $d_\\mathrm{v}=3$ to improve the performance. Determine a suitable coefficient $\\rho \\in [0,1]$ which determines the portion of variable nodes with degree $d_\\mathrm{v}=2$. Construct the EXIT chart and describe your observations!\n",
    "\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f2285-4956-43d1-bce9-172d47467efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
